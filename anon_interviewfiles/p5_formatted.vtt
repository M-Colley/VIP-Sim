00:00 --> 00:21.000
So, läuft ab jetzt. Dann starte ich hier noch kurz am Bildschirm die Aufnahme und dann kann es losgehen.
 
 Alles klar, gut. Dann erstmal einen guten Morgen. Ich bräuchte einmal dein Alter am Anfang.
 

Participant: 00:21.000 --> 00:23.000
Ich bin 62.
 

Researcher: 00:23.000 --> 00:27.000
Alles klar, richtiger Jungschund. Das Geschlecht?
 

Participant: 00:27.000 --> 00:29.000
Männlich.
 

Researcher: 00:29.000 --> 00:33.000
Hast du vielleicht einen aktuellen Visuswert?
 

Participant: 00:33.000 --> 00:35.000
Was heißt Visuswert?
 

Researcher: 00:35.000 --> 00:39.000
Deine aktuelle Sehschärfe oder dein Sehgrad?
 

Participant: 00:39.000 --> 00:47.000
Also pass auf, links gleich 0, also vielleicht höchstens noch ein halbes Prozent und rechts 5 Prozent.
 

Researcher: 00:49.000 --> 00:53.000
Okay, alles klar. Liegt bei dir eine akute Lichtempfindlichkeit vor?
 

Participant: 00:53.000 --> 00:55.000
Nein.
 

Researcher: 00:55.000 --> 00:57.000
Farbenblindheit?
 

Participant: 00:57.000 --> 00:59.000
Nein.
 

Researcher: 00:59.000 --> 01:06.000
Wie würdest du dein aktuelles Sichtfeld beschreiben? Gibt es Ausfälle jetzt explizit oder?
 

Participant: 01:06.000 --> 01:42.000
Ja, wie gesagt, links sehe ich erst, wenn jemand vor mir ist oder das, weil ich immer auf dem linken auch so gut wie gar nichts mehr sehe.
 
 Und rechts? Nein, Gesichtsfeldausfälle habe ich jetzt keine. Also ich sehe schon noch scharf und Ding.
 
 Aber ich darf jetzt mal so einen blöden Spruch, man sagt immer, oder so wird es definiert, das, was du halt in 20 Metern Entfernung siehst, muss ich auf einen Meter angehen.
 
 Das heißt, wenn ich jetzt zum Beispiel hier, ich kann den Bildschirm schon aussehen, aber ich kann jetzt sicher die Einfländlinger lesen.
 

Researcher: 01:42.000 --> 01:44.000
Okay, verstehe.
 

Participant: 01:44.000 --> 01:46.000
Zumindest nicht in der Größe.
 

Researcher: 01:46.000 --> 01:50.000
Und wann hat bei dir die Sehbehindrechtigung angefangen?
 

Participant: 01:50.000 --> 01:52.000
Von Geburt.
 

Researcher: 01:56.000 --> 02:01.000
Okay, hast du vielleicht eine medizinische Diagnose für deine Sehbehindrechte?
 

Participant: 02:01.000 --> 02:03.000
Ja, Grauer Star.
 

Researcher: 02:03.000 --> 02:05.000
Noch andere?
 

Participant: 02:08.000 --> 02:14.000
Ja, das weiß ich jetzt nicht alles aus, wenn ich hätte gesagt, hätte ich das Attest mitgebracht.
 

Researcher: 02:14.000 --> 02:22.000
Kein Problem.
 
 Genau.
 

Participant: 02:22.000 --> 02:26.000
Nystagmus hast ja gesehen, dass ich da die Augen nicht ruhig halten kann.
 

Researcher: 02:30.000 --> 02:34.000
Hast du aktuell eine Behandlung?
 

Participant: 02:34.000 --> 02:40.000
Nein, nein.
 
 Da gibt es nichts mehr zur Behandlung.
 

Researcher: 02:40.000 --> 02:52.000
Genau, wenn du jetzt so ein technisches Gerät, wie zum Beispiel so ein Smartphone, einen Bildschirm oder einen Fernseher verwendest, wie rückt sich das Ganze aus? Wo schränkt dich das da ein?
 

Participant: 02:52.000 --> 03:23.000
Also ich bin ja selber in der IT, ich arbeite da, das heißt ich bin in der Softwareentwicklung und ich vergröße mir die Bildschirminhalte eben mit der ganz normalen Windows-Lube.
 
 So, das gleiche gilt für das Smartphone, da gibt es ja auch so schöne Features, wie zum Beispiel diese Vergrößerung, was ich dann dazu sagen muss, ich benutze ausschließlich ein iPhone, weil es einfach barrierefreier ist.
 

Researcher: 03:23.000 --> 03:27.000
Was ist dann besonders barrierefrei beim iPhone?
 

Participant: 03:27.000 --> 04:03.000
Ja, zum einen die Vergrößerung, dann ist VoiceOver drauf. Also VoiceOver benutze ich jetzt nicht oft, aber manchmal eben schon, weil es dann auch einfach mal schneller geht.
 
 Und genauso benutze ich auch für große Texte oder für längere Texte, die lasse ich mir dann schon einmal vorlesen, mit irgendwelchen Screenreadern, da gibt es ja Sachen softwarefrei auf dem Markt verfügbar und das mache ich schon auch.
 
 Also wie gesagt, wenn ich jetzt, sagen wir mal, ich muss jetzt 20 Seiten lesen, die lasse ich mir vorlesen.
 

Researcher: 04:03.000 --> 04:05.000
Was dann einfach zu mühselig wäre?
 

Participant: 04:05.000 --> 04:11.000
Genau, weil du musst ja überlegen, wenn du eine Schrift vergrößerst, du musst ja immer hin und her fahren.
 

Researcher: 04:11.000 --> 04:17.000
Das stimmt, ja. Wie viel Prozent stellst du ungefähr die Bildschirmbufe, weißt du das auswendig?
 

Participant: 04:17.000 --> 04:51.000
Das kommt drauf an. Also wir haben jetzt so eine neue Java-Entwicklungsumgebung und da brauche ich schon eine ziemliche Vergrößerung, weil da einfach der Kontrast fehlt.
 
 Und angefangen habe ich mit IBM-Großrechner-Ansagen und da war einfach der Kontrast ein ganz anderer. Und heute haben wir schon einen Haufen Symbole und Fensterle und nochmal und da brauchen wir dann schon eine entsprechende Vergrößerung.
 
 Und das ist natürlich auch tagesformabhängig.
 

Researcher: 04:51.000 --> 04:54.000
Tagesformabhängig, okay. Das bedeutet?
 

Participant: 04:54.000 --> 05:13.000
Ja, das bedeutet, dass man manchmal mit einer geringen Vergrößerung zurechtkommt, aber manchmal eben nicht.
 
 Das ist auch der Fall. Wenn man jetzt, sagen wir mal, ich habe jetzt acht Stunden gearbeitet, dann merkt man dann schon nach und du wirst dann wieder ins Prozess und muss sich das entsprechend größerstellen.
 

Researcher: 05:13.000 --> 05:48.000
Ich verstehe. Ich habe vorhin gesehen, dass du dein Handy sehr nah gehalten hast und du hast es dir explizit vor ein Auge gehalten.
 
 Hast du das gemacht, weil es besonders unscharf war? Also wenn du es zu weit weghältst mit der Analogie von 20 Metern, dann nehme ich an, dass du das einfach größer machen wolltest?
 
 Oder hast du irgendwie besonders im Sichtfeld einen Bereich, wo du besser siehst nochmal auf dem besonderen Auge?
 

Participant: 05:48.000 --> 06:03.000
Also zum einen, ich kann es ja nur im rechten Auge überhaupt lesen. Im linken geht nichts.
 
 Dann habe ich mein Handy generell invers eingestellt, also weiße Schrift, dunklem Hintergrund.
 

Researcher: 06:03.000 --> 06:06.000
Okay, warum das, wenn ich fragen darf?
 

Participant: 06:06.000 --> 06:35.000
Weil das für mich einfach angenehmer ist. So wie bei dir hier auch. Das ist für mich einfach angenehmer.
 
 Ich finde auch, da ermüdet man nicht so schnell.
 
 Und wie gesagt, oftmals, wenn ich jetzt irgendeine Telefonnummer raussuche oder irgendwas, dann weiß ich ja schon in etwa.
 
 Ich kann es jetzt vielleicht nicht unbedingt jetzt explizit jeden Buchstaben lesen, aber ich weiß dann schon in etwa noch, was ich suche.
 

Researcher: 06:35.000 --> 06:42.000
Okay, gut. Jetzt sind wir mit dem ersten Teil durch, dem demografischen, dann würden wir jetzt an die Bilder gehen.
 

Participant: 06:42.000 --> 06:59.000
Und wie gesagt, wenn man es immer größer braucht, kann man sich größer zoomen. Nicht immer unbedingt überall, aber das iPhone bietet da schon sehr gute.
 
 Mit den zwei Fingern dann einfach größer machen.
 
 Jaja, jetzt gibt es da die Vergrößerung, da muss man dann halt mit Gestensteuerung das machen.
 

Researcher: 06:59.000 --> 07:02.000
Ah, okay, das kenne ich gar nicht. Wie funktioniert das dann?
 

Participant: 07:02.000 --> 07:37.000
Also man hat das Handy eingeschaltet, ganz normal, hat eine 1 zu 1-Bildschirm und sagt, ich will jetzt eine Vergrößerung.
 
 Da mache ich 1, 2, 3 und dann kann ich das entsprechend hin und her ziehen, dann ist die Vergrößerung an.
 
 Das ist quasi, wo sich dann natürlich die Katze ein bisschen im Schwanz beißt, du kannst VoiceOver und Vergrößerung nicht beides gleichzeitig benutzen.
 
 Weil die Befehle sind ähnlich.
 
 Und dann weiß das System ja nicht, was will er jetzt? Will er jetzt VoiceOver oder will er die Bildschirmvergrößerung?
 
 Also es geht immer nur eins.
 

Researcher: 07:37.000 --> 07:41.000
Verstehe, und die Befehle sind dann das Tippen?
 

Participant: 07:41.000 --> 07:51.000
Also du tippst dreimal auf den Bildschirm und dann geht ein Fernseher und dann kannst du mit dem Schieberegler die Vergrößerung einstellen.
 

Researcher: 07:51.000 --> 07:54.000
Und wo ist dann der Konflikt mit dem VoiceOver? Wie schaltet man den ein?
 

Participant: 07:54.000 --> 07:55.000
Genauso.
 

Researcher: 07:55.000 --> 07:56.000
Okay, verstehe.
 

Participant: 07:56.000 --> 08:02.000
Oder ich kann sagen, hey Siri, VoiceOver ein. Das geht auch. Das geht auch über Sprachsteuerung.
 

Researcher: 08:02.000 --> 08:34.000
Verstehe.
 
 Okay, dann würde ich weitermachen.
 
 Da muss ich jetzt die Software starten.
 
 Und hierbei fangen wir immer an, dass wir die Teilnehmenden mit, also da müsstest du dich einmal gerade vor den Monitors sozusagen sitzen.
 
 Genau, dann gucken wir mal, dass wir alle Teilnehmenden auf ungefähr die gleiche Entfernung zum Bildschirm zunächst bringen.
 
 Wenn dann nachher der Test weiter vorangeht, darfst du auch gerne so nah wie möglich an dem Bildschirm.
 

Participant: 08:34.000 --> 08:35.000
Okay.
 

Researcher: 08:35.000 --> 08:52.000
Also da bist du dann komplett frei. Wir können auch nachher noch gucken, dass wir ein bisschen mit dem Vergrößerungsglas dir helfen.
 
 Je nachdem, dass wir da halt hinkommen gemeinsam.
 
 Genau, du sitzt schon richtig weit weg. Und dann würde ich dann einfach mal mit dem ersten Test anfangen.
 
 Du siehst jetzt hier so ein Gitter.
 

Participant: 08:52.000 --> 08:53.000
Ja.
 

Researcher: 08:53.000 --> 09:05.000
Wie gut ist es dir möglich, das Gitter zu erkennen? Kannst du die einzelnen Linien auseinanderhalten gerade?
 
 Die kann ich auseinanderhalten. Und ich sehe auch hier in der Mitte das Fadentreutz. Also das sehe ich schon.
 
 Siehst du in der Mitte auch den weißen Punkt?
 

Participant: 09:05.000 --> 09:06.000
Ja.
 

Researcher: 09:06.000 --> 09:12.000
Okay, wenn du den weißen Punkt mal anfokussierst, gibt es irgendwelche Ausfälle oder Verzirrungen in dem Gitter?
 

Participant: 09:12.000 --> 09:13.000
Nein.
 

Researcher: 09:13.000 --> 09:27.000
Nein. Okay, alles klar. Dann machen wir mal das Bild an. Wir sehen jetzt hier so ein Bild.
 
 Hierbei kannst du mir gerne mal beschreiben, was du auf dem Bild so erkennen kannst und was du siehst.
 

Participant: 09:27.000 --> 09:45.000
Also ich sehe so ein Hütchen, ein Zebrastreifen. Also eigentlich in einer normalen Innenstadtszene würde ich es jetzt mal so beschreiben.
 
 Also Leute auf dem Zebrastreifen und im Hintergrund noch Autos und Häuser.
 

Researcher: 09:45.000 --> 09:48.000
Wie viele Menschen stehen da ungefähr?
 

Participant: 09:48.000 --> 09:53.000
ein zwei drei, vier.
 
 Okay.
 
 Also hier.
 

Researcher: 09:53.000 --> 09:57.000
Kannst du mir die Kleidung ein bisschen beschreiben von den Leuten?
 

Participant: 09:57.000 --> 10:15.000
Also zwei haben Warnwesten an und Hosen und zwei haben keine Warnwesten.
 
 Aber ganz detailliert kann ich es jetzt nicht beschreiben, aber eben auch Hose und Oberteil.
 

Researcher: 10:15.000 --> 10:23.000
Du kannst es mir nicht ganz detailliert beschreiben, weil es umscharf ist?
 
 Nein, weil es zu weit weg ist.
 
 Weil es zu weit weg ist?
 

Participant: 10:23.000 --> 10:24.000
Ja.
 

Researcher: 10:24.000 --> 10:27.000
Okay, das heißt es fühlt sich für dich sehr klein an, oder?
 

Participant: 10:27.000 --> 10:33.000
Ja, es ist einfach zu klein. Da müsste ich dann schon wirklich näher ran gehen, um mehr Details zu erkennen.
 

Researcher: 10:33.000 --> 10:41.000
Okay, verstehe.
 
 Gut, siehst du hier oben diese beiden, also in dieser Werbeanzeige hier oben?
 

Participant: 10:41.000 --> 10:42.000
Ja.
 

Researcher: 10:42.000 --> 10:46.000
Da sind diese beiden Kreise. Kannst du mir die ein bisschen beschreiben?
 

Participant: 10:46.000 --> 11:00.000
Ich sehe da jetzt im unteren, also im linken unteren, was soll ich sagen, im grünen Kreis und den oberen.
 
 Grau, würde ich mal sagen.
 

Researcher: 11:00.000 --> 11:02.000
Das sind in den Kreisen irgendwas drin?
 

Participant: 11:02.000 --> 11:03.000
Das sehe ich nicht.
 

Researcher: 11:03.000 --> 11:08.000
Okay, und wenn du mal so näher ran gehen möchtest, wie du willst?
 

Participant: 11:08.000 --> 11:16.000
Ja, nee, also detailliert. Ja, es ist ein Muster drin, aber detailliert kann ich es dann nicht beschreiben.
 

Researcher: 11:16.000 --> 11:18.000
Okay, dann würde ich einmal die Bildschirmlupe einschalten.
 

Participant: 11:18.000 --> 11:19.000
Ah, okay.
 

Researcher: 11:19.000 --> 11:21.000
Geht das jetzt besser?
 

Participant: 11:21.000 --> 11:23.000
Ja, natürlich, so geht es besser.
 

Researcher: 11:23.000 --> 11:28.000
Okay. Erkennst du noch was in den Kreisen?
 

Participant: 11:28.000 --> 11:40.000
Ja, das sind unterschiedliche Farbpunkte oder Farbschattierungen, also es sind schwarze Punkte.
 
 Dann haben wir hier so rötliche Schattierungen und graue Schattierungen.
 

Researcher: 11:40.000 --> 11:55.000
Okay, alles klar. Gut, dann mache ich mal weiter. Wir versuchen es einmal ganz kurz, ob es klappt, wenn nicht ist kein Problem.
 
 Neben den beiden Kreisen sind einfach Buchstaben. Kannst du die vielleicht lesen?
 

Participant: 11:55.000 --> 11:56.000
Die sehe ich nicht mal.
 

Researcher: 11:56.000 --> 12:02.000
Okay, die siehst du nicht, alles klar. Und jetzt rein aus den Kreisen, wenn du mal ganz näher an den Bildschirm ran gehst wieder.
 

Participant: 12:02.000 --> 12:14.000
Ach, im oberen Teil, ja. Ja, aber, ja gut. Also ich sehe zwar, dass da was steht, aber ich kann da nicht sagen, was es ist.
 

Researcher: 12:14.000 --> 12:16.000
Okay, alles klar. Ich mache mir nochmal die Bildschirmlupe an.
 

Participant: 12:16.000 --> 12:17.000
Ja.
 

Researcher: 12:21.000 --> 12:25.000
Moment, dann muss ich wieder auf den richtigen Punkt. So, wenn wir das jetzt nochmal versuchen, klappt das vielleicht so besser?
 

Participant: 12:25.000 --> 12:42.000
Das ist ein V, ein R, ein S, ein K, ein O. Nein, ein D, das ist ein D, das ist ein R. Und drunter ein N, ein H, ein C, ein S, ein O.
 
 Das ist ein O und ein K. Und hier unten wird es jetzt schwierig, weil der Kontrast halt auch schlecht ist.
 

Researcher: 12:42.000 --> 12:45.000
Okay. Geht die dritte Reihe noch?
 

Participant: 12:45.000 --> 12:57.000
Ja, S, O. Nee, das kann ein C sein. N, O, Z, V.
 
 Okay, genau. Aber wie gesagt, das hat der Kontrast halt auch.
 

Researcher: 12:57.000 --> 13:11.000
Verstehe, verstehe. Das heißt, siehst du dann, moment, ich versuche es mal zu formulieren, ist das dann Farbkleckse, die sich nicht unterscheiden lassen kontrastmäßig?
 
 Oder ist es so, dass die Buchstaben mit dem Hintergrund eher verschwinden?
 

Participant: 13:11.000 --> 13:42.000
Ich sehe die Buchstaben schon, aber jetzt zum Beispiel hier beim C. Ich muss aber schon genau hinschauen, ob es ein C oder ein O ist.
 
 Ich sehe halt quasi einen runden Buchstaben. Oder was halt immer schwierig ist, ist eine Groß-Kleinschreibung, ein großes Kuh, kleines Kuh oder irgendwas.
 
 Und wie gesagt, die Buchstaben hier N, Z, die eindeutig sind, das ist kein Problem.
 

Researcher: 13:42.000 --> 13:44.000
Okay. Alles klar.
 

Participant: 13:44.000 --> 13:49.000
Bei der anderen muss ich einfach halt entsprechend näher hingucken.
 

Researcher: 13:49.000 --> 13:58.000
Ich kann auch mal noch näher rangehen, oder? Das ist ja superschwer. Moment. So.
 

Participant: 13:58.000 --> 14:00.000
Ein bisschen runter.
 

Researcher: 14:00.000 --> 14:01.000
So hoch, oder?
 

Participant: 14:02.000 --> 14:12.000
C, N, H, Z. Die untere Reihe ist eine Katastrophe. Das ist ein absolut schlechter Kontrast. Also ganz unten, das sieht man ja kaum.
 

Researcher: 14:12.000 --> 14:34.000
Ja. Okay. Alles klar. Dann will ich dir noch ein zweites Bild zeigen wollen.
 
 Da haben wir jetzt so eine Benutzeroberfläche. Wenn du die wieder anguckst, kannst du mal sagen, was links im Bild ist und was rechts im Bild ist. Und in der Mitte.
 

Participant: 14:34.000 --> 14:58.000
Also ich würde mal sagen, das linke könnte ein Telefon sein, aber wenn man es nicht weiß, was es ist, ist es schwierig.
 
 In der Mitte ist ein Zeiger. Was könnte das sein? Keine Ahnung.
 

Researcher: 14:58.000 --> 15:03.000
Okay. Wenn du mal ganz näher rangehst in den Bild, so wie du dann auch mal mal...
 

Participant: 15:03.000 --> 15:11.000
Radio, FM, DHB, okay. Ach, das soll ein Lautsprecher simulieren, wahrscheinlich. Ja, aber was weiß ich?
 

Researcher: 15:11.000 --> 15:18.000
Das ist ein Funkturm, genau. Also hier ist auch wieder das Problem.
 

Participant: 15:18.000 --> 15:20.000
Telefon.
 

Researcher: 15:20.000 --> 15:30.000
Der Bildschirm ist zu klein, also auf diese Entfernung sind die Symboliken zu klein, um sie zu erkennen, weil sie dann eben praktisch zu unscharf werden.
 

Participant: 15:30.000 --> 15:58.000
Nee, sagen wir es mal so, wenn ich jetzt weiß, was es ist, also wenn ich tagtäglich mit dem arbeite, ist es überhaupt kein Problem. Dann weiß ich dann, was es geht.
 
 Aber wenn ich es jetzt so von der Ferne formiere und hier jetzt die Schrift nicht explizit lesen kann, da muss man schon genau...
 
 Also wie gesagt, das Telefon, das erkennt man hier, der Zeiger auch und das Symbol, ja gut, da muss man draufkommen.
 

Researcher: 15:58.000 --> 16:27.000
Okay, dann würden wir mal zum nächsten Teil der Studie kommen. Nur noch mal um das festzuhalten.
 
 Wenn du jetzt das Bild von hier aus anschaust, dann fühlt sich das Telefon, du weißt ja ungefähr, wie das Telefon aussah, weil du ja näher dran warst und jetzt bist du ja wieder 60 cm weg vom Bildschirm.
 
 Im Vergleich Nähe dran und 60 cm, wie verhalten sich die Bilder, wie verändert sich das Bild für dich?
 

Participant: 16:27.000 --> 16:58.000
Was heißt, wie verändert sich das Bild? Wie soll ich das beschreiben? Wenn ich jetzt näher rangehe, zum einen gucke ich ja nur auf das eine Symbol.
 
 Wenn ich jetzt so weg sitze, sehe ich ja alle drei. Wenn ich jetzt näher rangehe, gucke ich ja ganz gezielt auf das eine Symbol.
 
 Und damit wird das natürlich auch, das muss man sich jetzt so vorstellen, wenn ich jetzt näher rangehe, wird das immer größer.
 
 Aber von der Schärfe her oder so ändert sich nichts.
 

Researcher: 16:58.000 --> 17:00.000
Ach, es ändert sich nichts von der Schärfe?
 

Participant: 17:00.000 --> 17:10.000
Nee, von der Schärfe her, ob ich jetzt weit weg sitze oder nicht, sondern ich erkenne halt mehr Details, wenn ich näher rangehe, weil ich mich ja genau auf dieses eine konzentriere.
 

Researcher: 17:10.000 --> 18:02.000
Okay, verstehe. Gut, dann würde ich den Simulator mal kurz einschalten.
 
 So, und dann machen wir es noch einmal zu.
 
 Okay, wir versuchen jetzt verschiedene visuelle Effekte praktisch auf diesem Bild mal zu simulieren.
 
 Ich zeige dir die mal. Du kannst auch jetzt gerne jederzeit so nah an den Bildschirm, wie du willst. Ich kann ihn dir auch näher ran schieben.
 

Participant: 18:02.000 --> 18:04.000
Nee, lass mal ruhig stehen.
 

Researcher: 18:04.000 --> 18:09.000
Okay, alles klar. Nur falls es dir unangenehm ist, immer nach vorne zu beugen, kannst du auch noch ein Stück näher ran.
 

Participant: 18:09.000 --> 18:11.000
Nein, das ist nicht unangenehm.
 

Researcher: 18:11.000 --> 18:22.000
Gut, ich mache mal das erste an. Hast du vielleicht irgendwie punktuell so ein Problem, dass das Bild irgendwann mal so ausschaut?
 

Participant: 18:22.000 --> 18:23.000
Nein.
 

Researcher: 18:23.000 --> 18:49.000
Nein? Okay. Wenn ich jetzt das hier mal verändere, zum Beispiel, kommt das vielleicht hin an diese Wahrnehmung, dass zum Beispiel die Hörer oder vorhin auch die Leute das Bild mit den Hörern nehmen, kommt das hin, dass sich dann der Hörer vielleicht auf die Ferne so verändert?
 

Participant: 18:49.000 --> 18:51.000
Nein, also Unschärfen habe ich nicht.
 

Researcher: 18:51.000 --> 18:52.000
Okay.
 

Participant: 18:54.000 --> 19:04.000
Außer man hat ja einen Träne im Auge oder irgendwas, dann kann es schon mal vorkommen, dass man unscharf sieht, aber in der Regel nicht.
 

Researcher: 19:04.000 --> 19:15.000
Okay.
 
 Ich tue noch mal das erste Bild rein.
 
 So, bei Veränderung der Farbe?
 

Participant: 19:21.000 --> 19:28.000
Es ist eigentlich, von der Wahrnehmung her, eigentlich ändert sich da nichts.
 

Researcher: 19:28.000 --> 19:29.000
Ändert sich nichts?
 

Participant: 19:29.000 --> 19:35.000
Nö.
 
 Also ob die Hütle jetzt gelb oder rot sind, das ist eigentlich erwarscht.
 

Researcher: 19:35.000 --> 19:37.000
Okay. Aber siehst du eine Veränderung?
 

Participant: 19:37.000 --> 19:38.000
Ja, ja.
 

Researcher: 19:38.000 --> 19:39.000
Ja, die siehst du?
 

Participant: 19:39.000 --> 19:40.000
Ja.
 

Researcher: 19:40.000 --> 19:45.000
Ich bin jetzt mal für das Protokoll alle vier durchgegangen.
 
 Auch hier siehst du eine Veränderung?
 

Participant: 19:45.000 --> 19:50.000
Ja, hier macht es jetzt ja quasi die Hütle, die Farbe, schwächer oder raus.
 

Researcher: 19:50.000 --> 20:01.000
Okay. Jetzt noch mal oben zu den Buchstaben.
 
 Wenn ich jetzt mal hier zum Beispiel das Moment so einstellen.
 

Participant: 20:03.000 --> 20:04.000
Ja.
 

Researcher: 20:05.000 --> 20:12.000
Vielleicht mal ein bisschen ruhig.
 
 Dann wird das für dich dann schlechter zu lesen?
 

Participant: 20:12.000 --> 20:19.000
So etwas geht gar nicht.
 
 Okay.
 
 Es geht gar nicht, weil das ist dann viel zu wenig Kontrast und viel zu halb.
 
 Das geht gar nicht.
 

Researcher: 20:19.000 --> 20:23.000
Okay. Das heißt jetzt ist es dir auch nicht mehr möglich, die erste Zeile zu lesen zum Beispiel?
 

Participant: 20:23.000 --> 20:37.000
Nö. So nicht.
 
 Und mit Vergrößern vielleicht?
 
 Ja, das vielleicht schon, ja.
 
 Okay, die machst du mal rein.
 
 Ja, das geht schon noch.
 
 Okay.
 
 Ja, das geht schon noch.
 

Researcher: 20:37.000 --> 20:38.000
Und die zweite?
 

Participant: 20:38.000 --> 20:57.000
Die zweite geht auch noch, NHCS.
 
 Ja, das geht auch noch.
 
 Okay.
 
 Die dritte, ja, mit vielen, ja.
 
 Das ist immer so gut.
 
 Also jetzt weiß ich sehr schön, was drauf ist, aber wenn ich das jetzt das erste Mal sehe, würde ich es nicht so ohne weiteres hinkriegen.
 

Researcher: 20:57.000 --> 21:03.000
Okay. Hast du irgendwie so Verzerrungen im Bild auch manchmal, wie es jetzt hier dargestellt ist?
 

Participant: 21:04.000 --> 21:06.000
Nein, eigentlich nicht.
 

Researcher: 21:06.000 --> 21:15.000
Okay. Dann eine Frage zum Nystagnus, müsste die Welt manchmal so sein, dass es sich so wegzieht?
 

Participant: 21:15.000 --> 21:16.000
Nein, nein.
 

Researcher: 21:16.000 --> 21:19.000
Okay, wie äußert sich der Nystagnus bei dir in der Regel?
 

Participant: 21:19.000 --> 21:29.000
Der äußert sich halt so, wenn ich jetzt zum Beispiel mich mit dir unterhalte, dann ist es für mich schwierig dich jetzt immer exakt zu fixieren.
 

Researcher: 21:29.000 --> 21:32.000
Okay. Was passiert mit meinem Kopf?
 

Participant: 21:32.000 --> 21:46.000
Das ist nicht mit meinem Kopf, sondern das ist ja die Augen, oder beim Augenarzt eine typische Frage. Schauen Sie genau auf den Pfeil und folgen Sie dem Pfeil. Das kann ich nicht. Das geht nicht.
 

Researcher: 21:46.000 --> 21:51.000
Okay. Wird der Pfeil dann manchmal vielleicht so gedoppelt, wie jetzt hier?
 

Participant: 21:51.000 --> 21:58.000
Nein, das ist nicht gedoppelt, aber das jetzt genau da hingucken und das zu fixieren, das kann ich einfach nicht.
 

Researcher: 21:58.000 --> 21:59.000
Okay.
 

Participant: 21:59.000 --> 22:04.000
Du kennst ja dieses typische Prozedere, Gesichtsfeld einmessern und klar, das ist bei mir sinnlos.
 

Researcher: 22:04.000 --> 22:14.000
Okay, alles klar.
 
 Moment, schön. So Verdunkungen im Sichtfeld, hast du sowas?
 

Participant: 22:14.000 --> 22:16.000
Nein.
 
 Nein.
 

Researcher: 22:17.000 --> 22:21.000
Genau, so ein Flimmern vielleicht.
 

Participant: 22:28.000 --> 22:32.000
Ja, das sehe ich jetzt gar nicht. Hast du da jetzt irgendwas?
 

Researcher: 22:32.000 --> 22:42.000
Ja, also wenn ich hier zum Beispiel, ich versuche gerade mal einen Punkt zu finden, ich mache es mal so. Hier, so ein Unterschied vielleicht auf dem grünen Punkt der Sechs?
 

Participant: 22:42.000 --> 22:49.000
Nein, das sehe ich nicht.
 
 Okay.
 
 Okay, jetzt wird es unscharf.
 

Researcher: 22:49.000 --> 22:51.000
Das wird jetzt unscharf?
 

Participant: 22:51.000 --> 22:57.000
Hier oben. Oder, oder. Ja, da hast du einen Kontrast rausgenommen.
 

Researcher: 22:57.000 --> 22:59.000
Jetzt gerade eben?
 

Participant: 22:59.000 --> 23:04.000
Ja.
 
 Und jetzt?
 
 Jetzt sehe ich keine Veränderung.
 

Researcher: 23:04.000 --> 23:06.000
Und wenn ich ihn wieder anmache?
 

Participant: 23:06.000 --> 23:13.000
Noch einen.
 
 Ja, ist jetzt an?
 
 Das ist kaum erkennbar. Also für mich.
 

Researcher: 23:13.000 --> 23:16.000
Was passiert für dich gerade was im Bild?
 

Participant: 23:19.000 --> 23:26.000
Also wenn ich es nicht weiß, würde ich sagen nein. Ich sage jetzt auch einfach nein. Ich will es ja ehrlich machen.
 

Researcher: 23:26.000 --> 23:28.000
Okay, und weißt du es?
 

Participant: 23:28.000 --> 23:29.000
Bitte?
 

Researcher: 23:29.000 --> 23:30.000
Weißt du es?
 

Participant: 23:30.000 --> 23:31.000
Nein.
 

Researcher: 23:31.000 --> 23:33.000
Weil du gesagt hast, wenn ich es nicht weiß...
 

Participant: 23:33.000 --> 23:37.000
Ja, vorher anschauen, was ich gemacht habe. Nee, ich sehe es nicht. Für mich ist es gleich.
 

Researcher: 23:37.000 --> 23:39.000
Für dich ist es gleich? Okay.
 

Participant: 23:39.000 --> 23:47.000
Gut.
 
 Ja, jetzt wird der Bild schon wieder, ja, kontrastreicher.
 

Researcher: 23:48.000 --> 23:50.000
Also Lichtempfindlichkeit hattest du ja nicht?
 

Participant: 23:50.000 --> 23:51.000
Nein.
 

Researcher: 23:51.000 --> 23:57.000
Okay. So ein peripheriges Blickverlust auch nicht?
 

Participant: 23:57.000 --> 24:06.000
Nein. Also so, dass ich im Außenbereich nichts sehe und das habe ich nicht.
 
 Den klassischen Röhrenblick, ja.
 

Researcher: 24:06.000 --> 24:07.000
Den hast du nicht?
 

Participant: 24:07.000 --> 24:08.000
Nein.
 

Researcher: 24:08.000 --> 24:14.000
Also so eine Verbleichung oder eine Vergilbung oder vielleicht auch so eine zusätzlich Verdunkung des Bildes?
 

Participant: 24:14.000 --> 24:16.000
Nein.
 
 Nein, okay.
 

Researcher: 24:16.000 --> 24:19.000
Einfüllerscheidungen?
 

Participant: 24:19.000 --> 24:21.000
Was heißt einfüllen?
 

Researcher: 24:21.000 --> 24:26.000
Ich kann es dir hier mal zeigen. Also wenn wir zum Beispiel in die Mitte reingucken, was das Bild sowas macht.
 

Participant: 24:26.000 --> 24:29.000
Ach so.
 
 Nein.
 

Researcher: 24:29.000 --> 24:32.000
Okay. So ein Doppelsehen?
 

Participant: 24:32.000 --> 24:35.000
Auch nicht, okay.
 

Researcher: 24:38.000 --> 24:51.000
Moment, ich mache hier kurz was.
  
 Dass das Bild irgendwie so ein bisschen reingesogen wird, wie jetzt hier.
 
 Ist das irgendwas, was dich bekannt fühlt?
 

Participant: 24:51.000 --> 24:55.000
So habe ich gesagt noch nicht gesehen.
 
 Okay.
 

Researcher: 24:55.000 --> 24:57.000
Verdunklung im Sichtfeld auch nicht?
 

Participant: 24:57.000 --> 24:58.000
Nein, nein.
 

Researcher: 24:58.000 --> 25:01.000
Okay. Und manchmal so ein Flackern?
 

Participant: 25:01.000 --> 25:28.000
Also sagen wir mal so, höchstens wenn die Lichtverhältnisse ziemlich abwechseln.
 
 Also von total kräller Sonne dann irgendwo oder umgedreht ist eigentlich schlimmer.
 
 Also wenn man von irgendwo völlig dunklen, meinetwegen aus der Unterführung rauskommt und das krelle Sonnenlicht, ja,
 
 dann muss man erstmal klarkommen.
 
 Ja.
 
 Dann muss man erstmal dran gewöhnen.
 
 Okay.
 

Researcher: 25:28.000 --> 25:33.000
Gut.
 
 Jetzt ist Folgendes.
 
 Wir sind jetzt durch mit den Funktionen des Simulators.
 

Participant: 25:33.000 --> 25:35.000
Ja.
 
 Ja.
 

Researcher: 25:35.000 --> 25:41.000
Hattest du das Gefühl, der konnte dich jetzt irgendwie abdecken mit deiner Wahrnehmung?
 

Participant: 25:41.000 --> 25:47.000
Ja gut, sagen wir mal so.
 
 Vieles trifft auf mich einfach nicht zu.
 

Researcher: 25:47.000 --> 25:48.000
Ja.
 

Participant: 25:48.000 --> 26:06.000
Ja.
 
 Also so, was weiß ich, irgendwelche Ausfälle oder irgendwie, wie gesagt,
 
 für mich ist es halt auch immer schwierig, weil ich bin es ja nicht anders gewohnt.
 
 Ja.
 
 Vom anderen Geburt an bin ich es ja nicht anders gewohnt.
 
 Ich kann es mir nicht vorstellen, wie es sich jetzt für dich anfühlt.
 

Researcher: 26:06.000 --> 26:07.000
Ja.
 

Participant: 26:07.000 --> 26:16.000
Das ist immer die Schwierigkeit, die wir, sagen wir mal jetzt,
 
 Geburtsblinden oder Geburtssehbehinderten haben.
 
 Ich kenne es nicht anders.
 

Researcher: 26:16.000 --> 26:17.000
Ja.
 

Participant: 26:17.000 --> 26:22.000
Für mich ist das, wenn ich mich jetzt hier aus dem Fenster gehe,
 
 für mich ist das völlig normal.
 

Researcher: 26:22.000 --> 26:23.000
Ja.
 

Participant: 26:23.000 --> 26:24.000
Weil ich es nicht anders kenn.
 

Researcher: 26:24.000 --> 27:06.000
Natürlich.
 
 Ja.
 
 Verstehe.
 
 Wenn wir jetzt den Simulator weiterentwickeln wollen würden,
 
 und ich versuche jetzt anderen praktisch das,
 
 also für mich auch ersichtlich zu machen, wie du die Bilder jetzt wahrgenommen hast,
 
 zum Beispiel.
 

Participant: 27:06.000 --> 27:07.000
Ja, ja, ja.
 

Researcher: 27:07.000 --> 27:12.000
Ich habe vorhin die Unschärfe hier rein gemacht,
 
 dann meinst du, das trifft nicht zu.
 

Participant: 27:12.000 --> 27:13.000
Nein.
 

Researcher: 27:13.000 --> 27:22.000
Also das ist nicht deine Wahrnehmung.
 
 Wie müsste ich denn Bilder am besten darstellen,
 
 wenn das klappt?
 

Participant: 27:22.000 --> 27:23.000
Oha.
 

Researcher: 27:23.000 --> 27:33.000
Müsste ich die vielleicht kleiner machen,
 
 könnte das helfen, dass ich das Bild kleiner darstelle oder so?
 

Participant: 27:33.000 --> 27:55.000
Ja, das, also wie gesagt, ich sehe halt Details erst,
 
 wenn ich näher ran gehe, ja.
 
 Also ich sehe jetzt zum Beispiel hier auf deinem Rechner die Schrift,
 
 ich kann sie aber nicht lesen, ja.
 
 Ob die lesen zu können, müsste ich sie mir größer machen
 
 oder entsprechend näher ran gehen, ja.
 

Researcher: 27:55.000 --> 27:56.000
Ja.
 

Participant: 27:56.000 --> 28:18.000
In dem Fall wahrscheinlich sogar größer machen,
 
 weil das doch relativ klein ist.
 
 Und deswegen denke ich mal, wäre es vielleicht hilfreich,
 
 wenn man auch sagt, okay, ich habe auf der einen Bildschirmehälfte
 
 die normale Ansicht und auf der anderen Bildschirmehälfte
 
 mache ich das ziemlich klein.
 
 Klein, okay.
 
 Wenn du das auch nicht mehr siehst,
 
 dann hast du etwa eine Vorstellung, ja.
 

Researcher: 28:18.000 --> 28:19.000
Okay.
 

Participant: 28:19.000 --> 28:27.000
Und dann kannst du dir überlegen, je näher du der Sache kommst,
 
 umso quasi besser erkennst du das, was da drauf ist, ja.
 

Researcher: 28:27.000 --> 28:38.000
Das bedeutet, effektiv, wenn ich das Ganze umsetzen wollen würde,
 
 müsste jemand, das wird soweit verkleinern,
 
 dass am Ende des Tages ein Detailgradverlust passiert.
 

Participant: 28:38.000 --> 29:09.000
Ja, ja.
 
 Ich glaube, eine gute Vorstellung ist auch,
 
 ich nehme an, du fährst Auto, du bist auf der Autobahn.
 
 Ja.
 
 Dann gibt es jetzt diese Schilderbrücken, ja.
 
 Und du siehst das jetzt mal aus einer Entfernung von,
 
 was weiß ich wie viel, 100 Meter, ja.
 
 Da sehe ich zwar die Schilderbrücke, aber ich kann es nicht lesen.
 
 Lesen kann ich es eigentlich erst, wenn ich schon fast drunter durchpille.
 
 Okay.
 
 So muss man sich es vorstellen.
 
 Ja.
 

Researcher: 29:10.000 --> 29:15.000
Das heißt, am Ende des Tages müsste man den Detailgrad eines Bilds reduzieren,
 

Participant: 29:15.000 --> 29:16.000
ja.
 

Researcher: 29:16.000 --> 29:18.000
Ohnes im Wesentlichen Unschärfe zu machen.
 

Participant: 29:18.000 --> 29:28.000
Genau, ja.
 
 Ja, okay.
 
 Also Unschärfe ist bei mir absolut fehl am Platz,
 
 sondern wirklich einfach sagen, okay, das wird halt immer kleiner.
 

Researcher: 29:33.000 --> 30:13.000
Okay, verstehe.
 
 Das heißt, wenn du dir jetzt vorstellen würdest, als nächste Frage,
 
 dass ein Designer, der zum Beispiel sowas macht beruflich,
 
 also hier, sowas, ja.
 
 Wenn der jetzt so ein Tool verwenden würde,
 
 also zum Beispiel dieses Tool verwenden würde,
 
 um die Symptome von, ich weiß jetzt nicht,
 
 oder dass er zum Beispiel dieses Tool verwenden würde,
 
 um die Symptome von so Sehbehindrungen,
 
 oder insbesondere deine Sehbehindrungen, auch zu simulieren,
 
 was sind deine Gedanken dazu?
 
 Also benutzt du das in seinem Alltag, um das mal zu sehen,
 
 um das mal zu bemerken.
 

Participant: 30:13.000 --> 30:42.000
Das ist jetzt eine schwierige Frage.
 
 Ich meine, das ist, wie gesagt, das ist auch immer eine Frage,
 
 wie oft arbeite ich mit sowas.
 
 Wenn ich jetzt zum Beispiel, nenn mal an,
 
 ich arbeite jetzt bei mir am Bildschirm,
 
 dann sehe ich jetzt zum Beispiel hier die unteren Symbole nicht im Detail.
 
 Aber da ich jeden Tag dran arbeite, weiß ich, wo was ist.
 

Researcher: 30:42.000 --> 30:44.000
Okay, verstehe.
 

Participant: 30:44.000 --> 31:02.000
Und kann dann mit der Maus entsprechend drauf.
 
 Genauso das, das ist eigentlich nur das,
 
 bis man es das erste Mal gesehen hat und weiß, worum es geht.
 
 Und dann ist es, also die Größe von den Dingern,
 
 die wäre jetzt für mich absolut ausreichend.
 

Researcher: 31:02.000 --> 31:49.000
Okay, genau.
 
 Aber die, also tief die Frage, um die es geht,
 
 ist, also wenn du dir das vorstellst,
 
 ist das jemand wirklich, bei Mercedes zum Beispiel,
 
 das hier designt und wer dann dessen er das entwickelt,
 
 die mit Photoshop oder wie auch immer mit Programmen
 
 dieses Telefon hinzieht, hier dieses Navigation hinzieht
 
 und das dann einstellt in Form, Formgröße, Faktor, Farben und so weiter.
 
 Und währenddessen er das macht, benutzt er jetzt dieses Programm hier,
 
 das was ich immer auch hatte, diesen Simulator,
 
 um sich als Überlagerung auf das Bild,
 
 sich die visuellen Effekte anzugucken.
 
 Was sind da deine Gedanken dazu?
 
 Wie findest du das, die Vorstellung, dass jemand sowas macht?
 
 Während dem Designprozess sozusagen.
 

Participant: 31:49.000 --> 31:53.000
Also, ganz falsch verstehe ich es jetzt nicht.
 

Researcher: 31:53.000 --> 32:00.000
Okay, also, Entschuldigung, aber gar kein Problem.
 
 Das ist mir schon öfters passiert.
 

Participant: 32:00.000 --> 32:03.000
Ihr denkt wahrscheinlich hir eine Abstrakter.
 

Researcher: 32:03.000 --> 33:06.000
Ich versuche die Frage weniger abstrakt zu stellen.
 
 Also wenn ich morgens, also im hypothetischen Szenario,
 
 ich bin Entwickler von Software
 
 und ich mache GUIs, also Frontend.
 
 GUIs, Frontend, weißt du den Begriff?
 
 Also Benutzerschnittstellen, Benutzeroberfläche.
 
 Das Visuelle sozusagen.
 
 Dann wache ich morgens auf, fahre zur Arbeit
 
 und heute soll ich eine neue App erstellen, eine neue Applikation, ein neues Programm
 
 und davon die Benutzeroberfläche.
 
 Und jetzt möchte ich das machen
 
 und fange dann an dort Text reinzuschreiben in einer gewissen Größe,
 
 Bilder reinzuziehen.
 
 Und währenddessen ich das mache, benutze ich dieses Tool,
 
 was ich gerade gemacht habe, um zum Beispiel den Bildschirm unscharf zu machen
 
 oder diesen Auswahl in der Mitte, also das, was ich dir gerade eben gezeigt hatte,
 
 das benutze ich dann, um mir anzuschauen,
 
 wie das simuliert aussehen würde auf dem Gerät,
 
 letztendlich auf dem Bildschirm.
 
 Und diese Verwendung des Tools,
 
 was ist deine Meinung dazu, dass er das jetzt macht,
 
 in dem hypothetischen Szenario?
 

Participant: 33:06.000 --> 34:47.000
Ja gut, wenn ich mir das jetzt zum Beispiel vorstelle,
 
 du entwickelst das jetzt für ein Handy.
 
 Oder für einen Computerbildschirm oder irgendetwas.
 
 Was für mich halt immer,
 
 ich meine, ich mach halt in dem Fall nicht solche Benutzeroberflächen,
 
 für mich persönlich,
 
 mir ist eine einfache, simple Benutzeroberfläche
 
 immer noch das Liebste.
 
 Wo ich die nötigen Informationen drauf habe
 
 und den ganzen Schnickschnack.
 
 Das sage ich jetzt mal wirklich so salopp, auf den kann ich verzichten.
 
 Oder was wirklich eine absolute Katastrophe ist,
 
 finde ich auch, mir fällt jetzt gerade die Internetseite von unserer Gemeinde ein.
 
 Du gehst mit dem Mauszeiger irgendwo auf den Menüpunkt
 
 und dann klappt das irgendwo auf
 
 mit dem Mauszeiger irgendwo hin und dann ist es weg.
 
 Das ist eine Katastrophe für Leute, die schlecht sehen.
 
 Weil ich muss diese Sachen fixieren können.
 
 Ich muss sagen können, okay, ich habe jetzt ein Telefon,
 
 und es ist jetzt völlig wurscht, ob ich jetzt mit der Maus,
 
 rechts oder links oder wie auch immer mit dem Finger,
 
 ist egal, ich muss dieses Symbol fixieren können.
 
 Und dann nützt es mir nichts,
 
 sobald ich dann irgendwo mit der Maus woanders hinwander,
 
 wenn dann irgendwelche anderen Dinge aufgehen.
 
 Ich hoffe, das können wir kapieren.
 

Researcher: 34:47.000 --> 35:07.000
Ich verstehe, das wäre das Ziel, das wünschst du dir,
 
 dass das passiert mit zukünftigen Designs.
 
 Aber glaubst du vielleicht so ein Simulator,
 
 der dem Entwickler vielleicht hilft,
 
 ein Verständnis oder eine Vorvisualisierung zu bekommen
 
 von möglichen Sehbeginnungen?
 
 Glaubst du, das hilft ihm bei der Entwicklung?
 

Participant: 35:07.000 --> 35:13.000
Ich sage immer, das ist meine ganz persönliche Meinung.
 

Researcher: 35:13.000 --> 35:14.000
Darum geht es hier!
 

Participant: 35:14.000 --> 36:21.000
Ich sage immer, frag die Leute.
 
 Nein, weil du hast 20 Leute da sitzen.
 
 Jeder hat eine andere Augenkrankheit.
 
 Und jeder erzählt dir was anderes.
 
 Es gibt nicht die Lösung für alle.
 
 Die gibt es nicht.
 
 Wenn ich jetzt einen Blinden habe,
 
 dann kann ich sagen, da sieht nichts, fertig.
 
 Das können sich viele noch irgendwo vorstellen.
 
 Okay, da sieht halt nichts.
 
 Aber wenn du jetzt jemanden nimmst mit einer Sehbehinderung,
 
 dann ist jeder anders.
 
 Jeder hat eine andere Wahrnehmung.
 
 Und das macht so etwas schwierig.
 
 Und deswegen sage ich immer auch den App-Entwicklern,
 
 wir sind gerade auch dran, diese VVS in Stuttgart,
 
 diese App irgendwie auch barrierefrei hinzukriegen.
 
 Ich sage immer, frag die Leute.
 
 Lass es ausprobieren.
 
 Und die sagen dann schon, das ist scheiße und das ist gut.
 

Researcher: 36:22.000 --> 36:24.000
Okay.
 

Participant: 36:24.000 --> 36:31.000
Und wie gesagt, für mich gibt es nicht die Lösung, die eine.
 
 Die gibt es nicht.
 

Researcher: 36:31.000 --> 36:56.000
Okay, verstehe.
 
 Und das ist jetzt eine bisschen freier Frage.
 
 Man kann sich ja vorstellen, dass man im Prozess dann irgendwie
 
 kurz mal was gucken will.
 
 Man trifft ja am Tag als Designer ganz viele Entscheidungen.
 
 Also jede einzelne Entscheidung.
 

Participant: 36:56.000 --> 36:58.000
Was wäre da für dich eine Lösung,
 

Researcher: 36:58.000 --> 37:12.000
dass diese Entscheidungen auch fundiert getroffen werden?
 
 Also während dem Prozess.
 
 Das dauert ja immer so ein paar Jahre vielleicht sogar.
 
 Also für mich, wenn jetzt irgendetwas designt wird,
 

Participant: 37:12.000 --> 37:53.000
für mich ist es halt wichtig.
 
 Wie soll ich es jetzt formulieren?
 
 Die Information, die notwendig ist,
 
 um zu verstehen, was das Ding tut.
 
 Und auf völlig überflüssigen Kram einfach verzichten.
 
 Mir reicht es, wenn ich weiß, okay,
 
 ich habe jetzt hier so einen Mauszeiger
 
 und da steht, was weiß ich, Navigation darunter.
 
 Das reicht mir völlig.
 
 Das brauche ich nicht.
 
 Oder wenn ich jetzt hier habe ein Telefon, das reicht doch.
 

Researcher: 37:53.000 --> 37:56.000
Also einfach, einfache Interfaces.
 

Participant: 37:56.000 --> 38:35.000
Einfach, so einfach wie möglich.
 
 Weil für uns, sagen wir mal, für unseren Personenkreis
 
 ist das einfach wichtig.
 
 Oder jetzt für mich auch vor allem.
 
 Mir nützt das nichts, wenn ich tausend Informationen habe.
 
 Das nützt mir nichts.
 
 Ich muss auf das, egal ob das ein Computerbildschirm
 
 oder ein Handy ist oder ein Tablet ist,
 
 wurst, ich muss da drauf gucken können
 
 und sagen können, okay, das ist es, fertig.
 
 Und natürlich, was auch wirklich wünschenswert ist,
 
 ein vernünftiger Kontrast.
 
 Also hier in dem bild ist der Kontrast wirklich völlig in ordnung
 

Researcher: 38:37.000 --> 38:45.000
Hier oben waren wir ja da.
 
 War ja so ein Problem mit dem Kontrast bei Ihnen.
 

Participant: 38:45.000 --> 39:29.000
Ja, diese Schrift.
 
 Eine Werbeanzeige oder so.
 
 Wenn ich zum Beispiel, bei uns, wir haben jetzt auch eine Software
 
 oder besser gesagt, die wurde entwickelt,
 
 da sagt es den Leuten, hey Leute, da ist kein Kontrast.
 
 Die Schrift, die kannst du kaum lesen.
 
 Dann heißt es immer, ja, Gott, das entspricht der der DIN norm bla bla bla
 
 und bla bla bla, schieß mich tot.
 
 Also wenn ich da damit acht Stunden arbeiten müsste,
 
 würde ich euch das Zeug um die Ohren hauen.
 
 Das ist einfach, ich verstehe sowas nicht.
 
 Es geht ja nicht nur mir so, sondern sagen ja auch andere,
 
 also in Anführungszeichen Normalsehende,
 
 dass das einfach schwierig ist.
 
 Dann heißt es ja, ja, das entspricht der DIN und irgendwas.
 
 Das ist Müll.
 

Researcher: 39:29.000 --> 39:46.000
Ja.
 
 Okay.
 
 Das heißt, was ich machen könnte, wäre auch hier dann den...
 
 Moment, ich muss was einschalten.
 
 Ich könnte dann auch theoretisch den...
 
 Moment, das muss ich noch erfinden.
 

Participant: 39:46.000 --> 39:50.000
Ja, sowas.
 
 Keine Strophe.
 

Researcher: 39:50.000 --> 40:01.000
Genau, also mir zum Beispiel jetzt als Normalsehende Person,
 
 in Anführungszeichen, ist es jetzt auch nicht möglich,
 
 ab der dritten Zeile das zu lesen.
 
 Also das bekomme ich jetzt auch nicht mehr hin,
 
 wenn mir auch der Kontrast am Ende des Tages geht.
 

Participant: 40:01.000 --> 40:17.000
Nee, sowas.
 
 Das wäre ja genauso, wenn du daheim die Helligkeit...
 
 Genau.
 
 So kann kein Mensch was damit anfangen.
 
 Ja, genau.
 
 Aber ich könnte jetzt ja zum Beispiel sagen,
 
 für dich ist es jetzt zum Beispiel...
 

Researcher: 40:17.000 --> 40:22.000
Also ich konnte davor bis zum Beispiel bis zur sechsten Zeile lesen,
 
 du kannst jetzt nur noch bis zur dritten Seile lesen.
 

Participant: 40:22.000 --> 40:24.000
Ah, okay.
 

Researcher: 40:24.000 --> 40:55.000
Und bei dir war es ja so ungefähr erste, zweite, ohne Vergrößerung,
 
 mit der dritten dann auch noch mit Vergrößerung.
 
 Und jetzt kommen wir ja irgendwie vielleicht ein Stückchen näher, oder?
 
 Also dass ich sagen kann, ich erkenne jetzt, okay,
 
 Leute, die weniger kontrastreich sehen wie ich,
 
 die sollten jetzt ja Probleme haben.
 
 Weil ich kann es jetzt auch nicht mehr ab der dritten Seile lesen.
 
 Das heißt, wenn mir so wenig fehlt am Sehen,
 
 dass ich ab der dritten nur noch sehen kann,
 
 dann wäre jetzt vielleicht eine Designentscheidung,
 
 die ich treffen könnte, den Kontrast wieder hoch zu machen.
 

Participant: 40:55.000 --> 40:57.000
Genau.
 

Researcher: 40:57.000 --> 40:59.000
Das war eigentlich so die Idee vom Tool.
 

Participant: 40:59.000 --> 41:01.000
Ja, genau dieses.
 

Researcher: 41:01.000 --> 41:08.000
Also da soll dann eben praktisch so ein Tool helfen, wenn du das dann hast.
 
 Okay, aber ich nehme mit es kann halt auch nicht für jeden alleinheitlich eine Lösung geben.
 

Participant: 41:12.000 --> 42:45.000
Nein, die eine Lösung gibt es nicht.
 
 Und du musst überlegen, gerade in unserem Personenkreis,
 
 wir haben Leute, die normal in Anführungszeichen gesehen haben
 
 und dann irgendwann durch eine Augenkrankheit oder Unfall
 
 oder was auch immer erblinden oder eine Sehbehinderung.
 
 Bei denen ist es auch so ein schleichender Prozess.
 
 Das heißt, die haben ein gewisses Sehvermögen
 
 und das wird immer weniger.
 
 Dann gibt es die klassische Sehschwäche,
 
 dass dir irgendwelche Bereiche im Blickfeld einfach ausfallen.
 
 Du siehst halt nur noch irgendwo, wie muss man sich das vorstellen,
 
 du siehst einfach das Bild nicht mehr komplett,
 
 sondern du hast immer Punkte oder irgendwelche Flecken,
 
 die du eben nicht mehr siehst.
 
 Oder eben den klassischen, ich war erst letztens mit einer Dame unterwegs,
 
 da sagt sie zu mir, da vorne steht ein Bus, unser Bus,
 
 ich habe den Bus nicht mehr gesehen.
 
 Die Dame kann sich aber eigentlich nicht orientieren,
 
 weil die einen absoluten Röhrenblick hat.
 
 Das heißt, wenn die weiß, da vorne ist irgendwas, das sieht sie.
 
 Aber die nimmt ihre Umgebung nicht mehr.
 
 Nur diesen einen kleinen, witzigen Punkt.
 
 Du musst dir das so vorstellen,
 
 wenn du Papier nimmst, zusammenrollst und guckst dir das durch.
 
 So musst du dir das vorstellen.
 
 Dann siehst du auch, was um dich herum ist eigentlich nicht mehr.
 

Researcher: 42:45.000 --> 42:47.000
Dann musst du es so ein bisschen abscannen.
 

Participant: 42:47.000 --> 42:57.000
Ja, genau.
 
 Und dann musst du eigentlich immer permanent den Kopf drehen.
 
 Und deswegen, die eine Lösung, die gibt es einfach nicht.
 

Researcher: 42:57.000 --> 43:07.000
Alles klar.
 
 Dann sind wir an der Stelle durch.
 
 Möchtest du noch irgendwas loswerden?

Participant: 42:57.000 --> 43:07.000 
 Eigentlich nicht.

Researcher: 42:57.000 --> 43:07.000
 Dann würde ich an der Stelle die Aufnahme beenden.
 

